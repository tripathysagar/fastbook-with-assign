{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f24544bf-5be7-47ad-8f93-1ff188b30435",
   "metadata": {},
   "source": [
    "1. What is a \"feature\"?<br>\n",
    "    Unique transformation of data that can be helped to model data. Like edge detection will detect all the edges in the convolution early layers. \n",
    "1. Write out the convolutional kernel matrix for a top edge detector.<br>\n",
    "    \\begin{bmatrix} -1 & -1 & -1\\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1 \\end{bmatrix}\n",
    "1. Write out the mathematical operation applied by a 3×3 kernel to a single pixel in an image.<br>\n",
    "    Considering there is padding of size `1`. The pixel at (I, J) will be multiplied with all element of kernel.\n",
    "1. What is the value of a convolutional kernel apply to a 3×3 matrix of zeros?<br>\n",
    "    0's matrix\n",
    "1. What is \"padding\"?<br>\n",
    "    stacking dummy pixels(i.e 0) of size `ks//2` around the image.\n",
    "1. What is \"stride\"?<br>\n",
    "    jumping the kernel window in a image during consecutive convolution\n",
    "1. Create a nested list comprehension to complete any task that you choose.<br>\n",
    "    ```\n",
    "    >>> [[10 * i + j for j in range(10)] for i in range(2)]\n",
    "    [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]\n",
    "    ```\n",
    "1. What are the shapes of the `input` and `weight` parameters to PyTorch's 2D convolution?<br>\n",
    "    input : batch_size * in_channel * height * width <br>\n",
    "    weight : out_channel * in_channel * ks_height * ks_width\n",
    "1. What is a \"channel\"? <br>\n",
    "    data along specific dimensions. by combining all the channels data the original data is constructed. For 2d image channel is 1 for 3d it is 3.\n",
    "1. What is the relationship between a convolution and a matrix multiplication? <br>\n",
    "    to implement convolution via mat mult the weight matrix should be containing many `0` along with shared kernel.\n",
    "1. What is a \"convolutional neural network\"? <br>\n",
    "    use convolution to create initial NN insead\n",
    "1. What is the benefit of refactoring parts of your neural network definition?<br>\n",
    "    it much less likely you'll get errors due to inconsistencies in your architectures, and makes it more obvious to the reader which parts of your layers are actually changing.\n",
    "1. What is `Flatten`? Where does it need to be included in the MNIST CNN? Why?<br>\n",
    "    it removes the a given dimension if the end_dim is provided if nothing is given makes the tensor one dim.<br>\n",
    "    the last conv layer give the output to 1*1, to 1 dimensional to match the label\n",
    "1. What does \"NCHW\" mean?<br>\n",
    "    batch size * in_channel * height * width\n",
    "1. Why does the third layer of the MNIST CNN have `7*7*(1168-16)` multiplications?<br>\n",
    "    1168 params 16 bias and the operation is done with 7 * 7 grid\n",
    "1. What is a \"receptive field\"?<br>\n",
    "    The receptive field is the area of an image that is involved in the calculation of a layer\n",
    "1. What is the size of the receptive field of an activation after two stride 2 convolutions? Why?<br>\n",
    "    7 * 7, more deeper the layer the receptive area increases\n",
    "1. Run *conv-example.xlsx* yourself and experiment with *trace precedents*.\n",
    "\n",
    "1. Have a look at Jeremy or Sylvain's list of recent Twitter \"like\"s, and see if you find any interesting resources or ideas there.\n",
    "1. How is a color image represented as a tensor?<br>\n",
    "    3 * height * width\n",
    "1. How does a convolution work with a color input? <br>\n",
    "    conv across each channel adn sum at the result\n",
    "1. What method can we use to see that data in `DataLoaders`?<br>\n",
    "    dls.show_batch()\n",
    "1. Why do we double the number of filters after each stride-2 conv?<br>\n",
    "    the size of image decrese by 4. so we double the sifilter to learn higher no of features\n",
    "1. Why do we use a larger kernel in the first conv with MNIST (with `simple_cnn`)?<br>\n",
    "    to force the NN to learn as we deviding the input size by 4\n",
    "1. What information does `ActivationStats` save for each layer?<br>\n",
    "    record mean, std deviation, and actiavation of each layer\n",
    "1. How can we access a learner's callback after training?<br>\n",
    "    `learn.activation_stats.plot_layer_stats(-2)`\n",
    "1. What are the three statistics plotted by `plot_layer_stats`? What does the x-axis represent?<br>\n",
    "    mean, std, %near 0. batch size in x-axis\n",
    "1. Why are activations near zero problematic?<br>\n",
    "    the network did not contribute to learning\n",
    "1. What are the upsides and downsides of training with a larger batch size?<br>\n",
    "    adv : it summerizes the training data well(ie act as normilization)<br>\n",
    "    disadv : the memory rquired to train is very high\n",
    "1. Why should we avoid using a high learning rate at the start of training?<br>\n",
    "    the initial loss might be worse, if we act upon it and do step in gradient decent will worsen the params\n",
    "1. What is 1cycle training?<br>\n",
    "    combines learning rate warmup and annealing, which allows us to train with higher learning rates. \n",
    "1. What are the benefits of training with a high learning rate?<br>\n",
    "    we can jump over local minima and reach the final/optimal solution faster(super convergence)\n",
    "1. Why do we want to use a low learning rate at the end of training?<br>\n",
    "    to find the sweet spot of the loss function\n",
    "1. What is \"cyclical momentum\"?<br>\n",
    "    higher the learning rate lower the momentum and vice versa in lower learning rate \n",
    "1. What callback tracks hyperparameter values during training (along with other information)?<br>\n",
    "    `learn.recorder`\n",
    "1. What does one column of pixels in the `color_dim` plot represent?\n",
    "1. What does \"bad training\" look like in `color_dim`? Why?\n",
    "1. What trainable parameters does a batch normalization layer contain?\n",
    "1. What statistics are used to normalize in batch normalization during training? How about during validation?<br>\n",
    "    during training it user running mean and variance for each feature.\n",
    "    at validation we just have to use the learned parms in training\n",
    "1. Why do models with batch normalization layers generalize better?<br>\n",
    "    more random-ness to network and make the NN out less flactuate on the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2479e0-ec2b-4562-93cb-3c89ec42d373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[10 * i + j for j in range(10)] for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb311e-12b4-4d67-a3f2-b3258c68f9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4344,  1.5026, -1.1545],\n",
       "        [-0.2937,  0.4527, -0.2541],\n",
       "        [ 0.0553, -1.5838,  1.3602]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "A = torch.randn(4, 4)  # Shape: (3, 4)\n",
    "B = torch.randn(3,3)  # Shape: (4, 5)\n",
    "\n",
    "B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0820b161-311e-4870-8c50-3fc8e2d35d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3183)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = (A[0:3,0:3] @ B).sum()\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f84a0-e505-4f29-bd2a-35972705194a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4940, -0.7583,  1.0259, -1.8349],\n",
       "        [-1.1792,  0.4408, -0.2068, -1.0183],\n",
       "        [ 0.1546, -0.6246, -0.8864,  0.2593],\n",
       "        [ 1.5381, -2.1038, -2.1639,  1.5233]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a7d91-db20-4cbc-ac3f-54bd3883aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2843,  5.7471],\n",
       "        [ 1.7842,  5.7728]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = range(1,3)\n",
    "torch.tensor([[(A[i-1:i+2,j-1:j+2]*B).sum() for j in rng] for i in rng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70d323-4f26-43bb-bff4-989503c01400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[-1.4940, -0.7583,  1.0259],\n",
       "          [-1.1792,  0.4408, -0.2068],\n",
       "          [ 0.1546, -0.6246, -0.8864]]),\n",
       "  tensor([[-0.7583,  1.0259, -1.8349],\n",
       "          [ 0.4408, -0.2068, -1.0183],\n",
       "          [-0.6246, -0.8864,  0.2593]])],\n",
       " [tensor([[-1.1792,  0.4408, -0.2068],\n",
       "          [ 0.1546, -0.6246, -0.8864],\n",
       "          [ 1.5381, -2.1038, -2.1639]]),\n",
       "  tensor([[ 0.4408, -0.2068, -1.0183],\n",
       "          [-0.6246, -0.8864,  0.2593],\n",
       "          [-2.1038, -2.1639,  1.5233]])]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[A[i-1:i+2,j-1:j+2] for j in rng] for i in rng]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62056e7-389a-4ecf-b78b-f5bdc39193e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
