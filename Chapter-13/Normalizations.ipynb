{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5de34b-e63f-4d8b-9332-91733618ce55",
   "metadata": {},
   "source": [
    "## There are other normalization layers available in PyTorch. Try them out and see what works best. Learn about why other normalization layers have been developed, and how they differ from batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7971e9d-037a-4f1d-aeab-d7e1e5586a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343892e5-0fdf-44e3-813c-97bfdff0c967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/root/.fastai/data/mnist_png/testing'),Path('/root/.fastai/data/mnist_png/training')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1cbe5-61f2-41f1-a933-0bb8be28c9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(bs=64):\n",
    "    return DataBlock(\n",
    "        blocks = (ImageBlock(cls = PILImageBW), CategoryBlock),\n",
    "        get_items=get_image_files,\n",
    "        splitter=GrandparentSplitter('training', 'testing'),\n",
    "        get_y=parent_label,\n",
    "        batch_tfms=Normalize()\n",
    "    ).dataloaders(path, bs=bs)\n",
    "\n",
    "dls = get_dls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ab1071-beb0-455b-a451-e24c633a46a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=9, figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda608c3-346a-498a-99c2-6d888aebc50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    return sequential(\n",
    "        conv(1, 8, ks=5),\n",
    "        conv(8, 16),\n",
    "        conv(16, 32),\n",
    "        conv(32, 64),\n",
    "        conv(64, 10, act=False),\n",
    "        Flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba5db3c-6db4-427c-9341-9837979f4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs = 1, lr=0.06):\n",
    "    learn = Learner(dls, simple_cnn(), loss_func=CrossEntropyLossFlat(),\n",
    "                    metrics=accuracy)\n",
    "    learn.fit_one_cycle(epochs, lr)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184560d-ad2e-4b15-9e9e-86dde501b868",
   "metadata": {},
   "source": [
    "**Description**<br>\n",
    "`BatchNorm2d` for normalizing the activations of convolutional layers. It computes the mean and standard deviation of each feature map across a mini-batch of data and normalizes the activations accordingly. Additionally, BatchNorm2d introduces learnable parameters (weight and bias) that allow the network to adjust the normalized activations during training. \n",
    "During inference a running avg and std deviation is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd566e57-d297-4705-88e9-3c88a6ac173a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.106958</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.979800</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.045697</td>\n",
       "      <td>0.030825</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv(ni, nf, ks=3, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
    "    layers.append(nn.BatchNorm2d(nf))\n",
    "    if act:\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "learn = fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d68e41-465d-4260-b6b9-1d736c9e3382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = learn.model\n",
    "m1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bcd44a-b05e-4bf6-9435-f98e427a03f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1.1920, 3.3186, 3.0053, 1.7383, 1.1658, 1.8330, 1.5459, 3.0281],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.5849,  0.1569,  0.3826,  0.5174, -0.1117, -0.2501, -1.4828, -0.6511],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0][1].weight, m1[0][1].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f120bc-02dc-4812-83a2-a193974892ed",
   "metadata": {},
   "source": [
    "**Description**<br>\n",
    "`LazyBatchNorm2d` is a lightweight alternative to BatchNorm2d. Unlike `BatchNorm2d`, it does not have learnable parameters (such as weight and bias) and relies solely on input statistics for normalization.\n",
    "\n",
    "**Benefits**<br>\n",
    "*Memory Efficiency*: Since LazyBatchNorm2d does not require additional memory for learnable parameters, it is more memory-efficient compared to BatchNorm2d.<br>\n",
    "*Simplified Implementation*: By avoiding the introduction of learnable parameters, LazyBatchNorm2d simplifies the implementation of neural network architectures, making it easier to manage and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b481c-dac4-4448-a386-303686bfa5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.123992</td>\n",
       "      <td>0.081495</td>\n",
       "      <td>0.976000</td>\n",
       "      <td>00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.047296</td>\n",
       "      <td>0.033676</td>\n",
       "      <td>0.990200</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv(ni, nf, ks=3, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
    "    layers.append(nn.LazyBatchNorm2d())\n",
    "    if act:\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "learn = fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b17f5-8258-45ad-a790-304b021dd67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvLayer(\n",
       "  (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (1): BatchNorm2d(8, eps=8, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = learn.model\n",
    "m1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec81d29-c4be-47b3-82fa-34697821cb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1.5497, 2.4985, 1.1268, 1.8460, 1.3437, 2.1818, 1.0804, 1.0803],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.5212,  0.4667, -1.6717,  0.1338,  0.6302, -0.2084, -0.7283,  0.3781],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0][1].weight, m1[0][1].bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7a320-4493-46ca-86e6-88d6d6493b23",
   "metadata": {},
   "source": [
    "**GroupNorm**<br>\n",
    "Applies Group Normalization over a mini-batch of inputs.<br>\n",
    "The mean and standard-deviation are calculated separately over the each group. γ and β are learnable per-channel affine transform parameter vectors of size num_channels if affine is True.\n",
    "\n",
    "*Defination* : torch.nn.GroupNorm(num_groups, num_channels, eps=1e-05, affine=True, device=None, dtype=None) <br>\n",
    "`num_channels` should be devisible by `num_groups`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061b8f1-53fc-4db3-a165-08d41949b30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.159094</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>0.970400</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.062155</td>\n",
       "      <td>0.057904</td>\n",
       "      <td>0.985500</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv(ni, nf, ks=3, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
    "    layers.append(nn.GroupNorm(2, nf))\n",
    "    if act:\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "learn = fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fbd845-adc4-450a-88d4-2ab06a3c7193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (1): GroupNorm(2, 8, eps=1e-05, affine=True)\n",
       "  (2): ReLU()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = learn.model\n",
    "m1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead1e66a-d08d-41a8-8b37-3f729721e578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([1.0456, 0.9250, 1.7239, 1.5443, 1.6327, 0.9341, 1.1175, 1.3761],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4639, -0.1354,  0.0647, -0.0583, -0.2727, -0.2239, -0.5266, -0.4883],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1[0][1].weight, m1[0][1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b8dca-b314-4c47-b6e8-8caab5352b02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/937 00:00&lt;?]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 spatial element when training, got input size torch.Size([64, 10, 1, 1])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m         layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mReLU())\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nn\u001b[38;5;241m.\u001b[39mSequential(\u001b[38;5;241m*\u001b[39mlayers)\n\u001b[0;32m----> 7\u001b[0m learn \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 4\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(epochs, lr)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.06\u001b[39m):\n\u001b[1;32m      2\u001b[0m     learn \u001b[38;5;241m=\u001b[39m Learner(dls, simple_cnn(), loss_func\u001b[38;5;241m=\u001b[39mCrossEntropyLossFlat(),\n\u001b[1;32m      3\u001b[0m                     metrics\u001b[38;5;241m=\u001b[39maccuracy)\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mlearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_one_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m learn\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/callback/schedule.py:119\u001b[0m, in \u001b[0;36mfit_one_cycle\u001b[0;34m(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    116\u001b[0m lr_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([h[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mhypers])\n\u001b[1;32m    117\u001b[0m scheds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, lr_max\u001b[38;5;241m/\u001b[39mdiv, lr_max, lr_max\u001b[38;5;241m/\u001b[39mdiv_final),\n\u001b[1;32m    118\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmom\u001b[39m\u001b[38;5;124m'\u001b[39m: combined_cos(pct_start, \u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoms \u001b[38;5;28;01mif\u001b[39;00m moms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m moms))}\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mParamScheduler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_opt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_opt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_epoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:264\u001b[0m, in \u001b[0;36mLearner.fit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt, start_epoch)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mset_hypers(lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;28;01mif\u001b[39;00m lr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lr)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch \u001b[38;5;241m=\u001b[39m n_epoch\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelFitException\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_cleanup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:253\u001b[0m, in \u001b[0;36mLearner._do_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_epoch):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;241m=\u001b[39mepoch\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelEpochException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:247\u001b[0m, in \u001b[0;36mLearner._do_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_epoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_epoch_validate()\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:239\u001b[0m, in \u001b[0;36mLearner._do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_epoch_train\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdls\u001b[38;5;241m.\u001b[39mtrain\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelTrainException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:205\u001b[0m, in \u001b[0;36mLearner.all_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall_batches\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl)\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mone_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:235\u001b[0m, in \u001b[0;36mLearner.one_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m    233\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_device(b)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(b)\n\u001b[0;32m--> 235\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_with_events\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_one_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCancelBatchException\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:199\u001b[0m, in \u001b[0;36mLearner._with_events\u001b[0;34m(self, f, event_type, ex, final)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_with_events\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, event_type, ex, final\u001b[38;5;241m=\u001b[39mnoop):\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ex: \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_cancel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m);  final()\n",
      "File \u001b[0;32m/home/sagar/git/fastai/fastai/learner.py:216\u001b[0m, in \u001b[0;36mLearner._do_one_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_one_batch\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28mself\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_pred\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myb):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:87\u001b[0m, in \u001b[0;36m_InstanceNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_no_batch_dim():\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_no_batch_input(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_instance_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/instancenorm.py:36\u001b[0m, in \u001b[0;36m_InstanceNorm._apply_instance_norm\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_instance_norm\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minstance_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2525\u001b[0m, in \u001b[0;36minstance_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, use_input_stats, momentum, eps)\u001b[0m\n\u001b[1;32m   2512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2513\u001b[0m         instance_norm,\n\u001b[1;32m   2514\u001b[0m         (\u001b[38;5;28minput\u001b[39m, running_mean, running_var, weight, bias),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2522\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m   2523\u001b[0m     )\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_input_stats:\n\u001b[0;32m-> 2525\u001b[0m     \u001b[43m_verify_spatial_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minstance_norm(\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, running_mean, running_var, use_input_stats, momentum, eps, torch\u001b[38;5;241m.\u001b[39mbackends\u001b[38;5;241m.\u001b[39mcudnn\u001b[38;5;241m.\u001b[39menabled\n\u001b[1;32m   2528\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:2493\u001b[0m, in \u001b[0;36m_verify_spatial_size\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m   2491\u001b[0m     size_prods \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m size[i]\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_prods \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2493\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected more than 1 spatial element when training, got input size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 spatial element when training, got input size torch.Size([64, 10, 1, 1])"
     ]
    }
   ],
   "source": [
    "def conv(ni, nf, ks=3, act=True):\n",
    "    layers = [nn.Conv2d(ni, nf, stride=2, kernel_size=ks, padding=ks//2)]\n",
    "    layers.append(nn.InstanceNorm2d(nf))\n",
    "    if act:\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "learn = fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d9037-4d7e-475b-8b28-6211b49a2e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289d505-5ca3-45c6-9720-ba184ac1d88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = torch.randn((2,3))\n",
    "t2 = torch.randn((2,3))\n",
    "t1.m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
